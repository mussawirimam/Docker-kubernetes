
##### HELP COMMANDS USAGES
kubectl options label # The following options can be passed to any command: ...
kubectl --help
kubectl [flags] [options]
kubectl run --help
      Usage:
  kubectl run NAME --image=image [--env="key=value"] [--port=port] [--dry-run=server|client] [--overrides=inline-json]
[--command] -- [COMMAND] [args...] [options]
#####

## we were able to achieve the high availabilty through Docker Swarm using 3 nodes
## Master node (manager/leader) and 2 worker nodes

## manager node was managing 
## in docker swarm, we were missing few of the feature. If you are creating few of the application in pods with 3 replicas in each 3 nodes.
if  container1 is failed, container2 will serve the traffic. But if somehow there is more load and if the 3 replicas are not able to serve the traffic,
then you might have monitoring tool let's say you get a mail if the cpu usage/traffic got increased. You will be logging in the node and you 
will scale up the relicas. 

Assume let's say you have created 10 containers and after sometime the traffic went down, additional containers will keep on running on the container
you will have to again log in into the docker manager and scale it down. The ability for it to scale up and scale down is missing from Docker Swarm. 
For this reason, you would use the Kubernetes feature called Auto-Scaling. 

## Kubernetes has more features compared to Docker Swarm
# configMap is used to keep the configuration at the centralized place
# if you deploy any application it gets deployed to manager/leader as well but in kubernetes you can turn on or turn off this feature.
# there are lot's of features missing from Docker Swarm compared to Kubernetes

## multi-flavors of kubernetes:
On-prem
managed k8s
AWS --> EKS Elastic Kubernetes Service
GCP --> GKE Google Kubernetes Engine
Azure --> AKS Azure Kubernetes Service
# the difference would be with clustrter creations, because their cloud provider are having different user interfaces. Their looks and dashboard would be different
and cluster creation method would be different. 

to achieve high availabilty on-prem you will have to deploy the multiple Master node and these nodes would be managed by you only for high availability and similarly,
you would have to create multiple worker nodes. These master nodes will not be getting your deployment. Master node will not have your application deployed,
you will have the application deployed in worker and you would need a special admin to make sure it is always up and running which is a down side of On-Prem kubernetes, 
that is why you need managed kubernetes cloud provides. 


------------------------------------------------------------------------------------
some topics object to learn in our session:
Deployment
Satefulset
ConfigMap
Secrets
------------------------------------------------------------------------------------


You can define 
min-3 
or 
max-10 

You are responsible for upgrading/updating the kubernetes on-prem. If you are not updating/upgrading the On-Prem Kubernetes, you will be seeing deprecated work in kubernetes.

If you are not updating kuberenetes on Cloud version will have getting expired and if you are not updating the, your master node will automatically gets updated.
Auto-Upgradation feature is for Cloud-providers.

On-Premise depends on platform like linux, you will have to be executing commands like adding a user and then you will have to add RBAC
------------------------------------------------------------------------------------
RBAC: role based access control
on-prem
linux - adduser role/cluster-role role-bindling/cluster-rolebinding

cloud
## you will have the IAM and then you have to implement the role/cluster-role role-bindling/cluster-rolebinding
aws-create user from IAM - role/cluster-role role-bindling/cluster-rolebinding
GCP- IAM - role/cluster-role role-bindling/cluster-rolebinding
AZURE-activedirectory with IAM - role/cluster-role role-bindling/cluster-rolebinding

if you are talking about gcp and azure cloud, what I found is that these two types of kubernetes it is supereasy, you dont have to bother for plugin installation and configuration. Multiple types of configuraiton is required during cluster creation 
, you can enable auto-scaling once cluster is created, you can spin up volumes in these two cloud withtout any additional configuration, you can create load-balancers as well. These are the most used objects that is automatically enabled or configured.
In case of aws (eks), it is more secure and eadch and every step you will have to install and configure the plugin. If you are thinking to provision dynamic volume, so you will have to install and configure storage class in your EBS sci driver needs to be installed in cluster then only you will be able to spinup the volume.
If you guys want to spin up the load balancer, then again you will have to install and configure the aws cloud load balancer. 

------------------------------------------------------------------------------------

PRE-REQUISTES:
docker
yaml
cloud
virtualbox to setup lab environment on local box
linux

What Does kubernetes mean? 
Greek for "pilot" or "Helmsman of a ship"

What is kubernetes? 
. Kubernetes is an open-source Container Orchestration/Management tool which automates container deployment, container (de)scaling & container load balancing.
. Written on Golang, it has a huge community because it was first developed by Google & later donated to CNCF 
. Can group 'n' no of containers into one logical unit for managing & deploying them
. Built from the lessons learned in the experiences of developing and running Google's Borg and Omega.

Redhat has a paid version called Openshift, you pay for the license 
minimum node required t2 x.large on ec2


Decouples Infrastructure and Scaling:
. All services within Kubernetes are natively Load Balanced.
. Can scale up and down dynamically.
. Used both to enable self-healing and seamless upgrading or rollback of applications.

Self-healing:
Self Healing
Kubernetes will ALWAYS try and steer the cluster to Its desired state.
• Me: "I want 3 healthy instances of redis to always be running."
• Kubernetes: "Okay, I'll ensure there are always 3 instances up and running."
• Kubernetes: "Oh look, one has died. I'm going to attempt to spin up a new one."

Most importantly:
Use the SAME API across bare metal and
EVERY cloud provider!!!

Who "Manages" Kubernetes?

CLOUD NATIVE
COMPUTING FOUNDATION
Seif Hesting
The CNCF is a child entity of the Linux Foundation and operates as a vendor neutral governance group.
cncf.io

CERTIFICATION:
https://www.cncf.io/training/certification/

DISCOUNTED TRAINING:
https://training.linuxfoundation.org/?campaignid=21372675077&adgroupid=171974510868&creative=704304945812&matchtype=e&network=g&device=c&keyword=linux%20foundation&hsa_acc=8666746580&hsa_cam=21372675077&hsa_grp=171974510868&hsa_ad=704304945812&hsa_src=g&hsa_tgt=kwd-319242482088&hsa_kw=linux%20foundation&hsa_mt=e&hsa_net=adwords&hsa_ver=3&gad_source=1&gbraid=0AAAAAD2R-lqYs1f5JccR8X0Z0XEpEYFYL&gclid=Cj0KCQjww5u2BhDeARIsALBuLnPKA0ns6K4LlCnlwpvNZPF3A7MDmDpbJte2TWF-fuc326P4tu0IdVIaAr_sEALw_wcB&utm_source=google&utm_medium=paid-search&utm_campaign=24q2-evergreen-lf_training&utm_term=tnc-na-search-lf-brand&utm_content=eg_rsa&utm_term=linux%20foundation&utm_campaign=T%26C+-+NA+-+Search+-+LF

PODS:
Atomic unit or smallest
"unit of work"of Kubernetes.
• Pods are one or MORE containers that share volumes, a network
namespace, and are a part of a single context.

In Docker and Docker swarm, we were creating containers directly. In kubernetes, first you have to create the pods and in the pods, you can create the containers. 
and your pods will be deployed in the Host (vms/ec2)

⠀⠀⣤⠶⠶⠶⠶⠶⠶⠶⠶⠖⠶⠶⠶⠶⠶⠶⠶⠶⠶⠶⠶⠶⠖⠶⠶⠶⠶⠶⠶⠶⠶⠶⠶⠶⠶⠶⠶⠶⠶⠶⠶⠶⠶⠶⣄⠀⠀
⢀⣾⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀HOST A     ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⣧⢀
⢸⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢹⢸
⢸⡯⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠨⠀
⢸⡥⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠨⢰
⢸⡷⠀⠀⠀⣀⡀⢠⡤⣤⢄⣄⢀⡄⢀⢀⣄⢠⣤⣤⣤⣤⠠⠠⢠⢀⠄⠤⡄⣤⡀⣀⣀⡀⢠⡀⣠⣄⡀⢠⡠⣠⣄⣀⠀⠀⠀⢸⠀
⢸⣿⠀⣠⠋⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀POD  ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠑⡄⠀⢸⢐
⢸⣿⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠀⠉⠉⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢱⠀⣞⠀
⢸⣗⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣒⢠
⢸⣧⠀⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⠈
⢸⣿⠀⡇⠀⠀⠀⠀⠀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⣀⠀⠀⠀⠀⠀⠀⢸⢨
⢸⣿⠀⡇⠀⡏⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⡇⠀⠀⠀⣾⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⣿⠀⠈⠀⠸⠈
⢸⡯⠀⡇⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⣻⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⠀⡄⠀⢨⢰
⢸⣿⠀⡇⠀⡇⠀⠀⠀⢀⣀⣀⣀⣀⣀⣀⣀⣀⡀⠀⠀⠀⡇⠀⠀⠀⣿⠀⠀⠀⢀⣀⣀⣀⣀⣀⣀⡀⣀⡀⠀⠀⠀⣿⠀⠀⠀⢹⢘
⢸⣿⠀⡇⠀⡇⠀⠀⠀⠘CONTAINER⠃⠀⠀⠀⡇    ⡇   CONTAINER  ⠀⠀⠀⣿⠀⠁⠀⢸⢰
⢸⣿⠀⡇⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⣹⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⠀⠀⠀⢸⠘
⢸⣟⠀⡇⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⠀⠀⠀⣺⢠
⢸⣿⠀⡇⠀⠳⠤⠤⠤⠤⠤⠤⠤⠤⠤⠴⠶⠤⠤⠤⠤⠤⠇⠀⠀⠀⠻⠤⠤⠴⠶⠤⠴⠶⠶⠦⠤⠴⠶⠶⠤⠤⠴⠟⠀⢀⠀⣿⠸
⢸⣿⠀⢳⠀⠀NETWORK NAMESPACE 10.255.16.3⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⡞⠀⡿⢠
⢸⣽⠀⠀⠑⠠⠽⠿⠿⠽⠯⠥⠯⢿⡿⠽⠿⠿⠯⠵⠿⠶⠯⠾⡮⠽⠿⠯⠥⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠤⠔⠊⠀⠀⢽⢸
⠈⣯⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢾⠧⠀⠀⠀⠀⠀⠀⠀⠀⠰⡿⠄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡽⠘
⠀⠙⠳⢤⣄⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣄⣤⣧⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⣤⠞⠁⠀
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣸⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⣀⣀⣀⣀⣀⣀⣀⣀⣹⣃⣀⣀⣀⣀⣀⣀⣀⡀⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⡏⠀⠀⠀        ⠁⠀⠀⠀ ⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⡇⠀⠀⠀⠀⠉⣭External⠀⠀⠀⡇⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⡇⠀⠀⠀⠀⠀⠉⠛volume ⠀⠀⠀⡇⠀⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⠀⠀⠀⠀⠀⠉⠉⠉⠛⠛⠛⠉⠉⠉⠉⠉⠉⠉⠛⠛⠉⠉⠁⠸⡿⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
⢠⣿⠋⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠙⠛⠋⠙⠛⠛⠋⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠉⠙⠛⢿⠀
⢸⡏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀POD Network  ⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⠀
⢸⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠀⠀⠁⠀⠀⠀⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⠀
⠈⢛⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⠒⣛⠀

