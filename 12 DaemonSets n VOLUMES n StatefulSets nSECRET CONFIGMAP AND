########## DAEMONSET ##########
# let's suppose you have 3 workder node and I have to deploy application pod in each of the worker node
# till now we deploy the replicas of our pod through replicaController, ReplicaSet, and deployment. 
# Now see that, if you are going with above objects, they will create the replicas but doesnt guarantee that my application will be deployed in each of the worker node
# Let's suppose I am having some of the application which is primarily using for logging and monitoring
# whenever we are trying to deploy some of the logging monitoring application like ELK file beat monitoring applications
# these application should be deployed in each of the worker node, so that we able to collect logs and metrics.
# In this situation, the deployment will not be helping you out! Why?
# it will be guaranteeing you to define the number of replicas, but it will not guaranteeing you that it's replica will be going in each of the worker nodes. 

# the thing is that, I want to deploy the pod replica in each of the worker node. Let's assume that, my pod got deployed in each of the node.
# I have three worker nodes. Somehow, worker node3 is not up and running. The pod will not be getting deployed somewhere. It will be in its place. 
# if I add one more node in cluster, a new pod will be deployed in the new node in the cluster. 
node1
node2
node3

node4 

### IMPORTANT
### whenever we deploy an application, which is required to run on the each of the node. Then we will go for the DaemonSets
### what kind of those application can be? 
### logging and monitoring application, to collect the logs and metrics. Such applications requires to go and deployed in each of the node, so that we can collect information
# from the each of the worker node. It could be logging or metric (cpu or memory) We will go for the DAEMONSET

### what is the need for DaemonSet?
# A DaemonSet is a Kubernetes resource used to ensure that a specific pod is running on all (or some) nodes in a Kubernetes cluster. It plays a crucial role in scenarios where you need to deploy background tasks,
#monitoring agents, log collectors, or other system-level services across every node in the cluster.

### once you are creating DaemonSet, your pod will be getting created in each of the worker node. You dont need to define the number of replicas, it depends on the number of worker nodes.
# you can deploy a daemonset on the master node as well if it is an on-prem server or cop server.
# if it is a cloud kubernetes, you can see master node server on cloudwatch or some other services.
# if some worker node is failing or going down. What will happen is, in such scenerio the pod will node be re-scheduling on other nodes.
# if the worker node is back again, the pod will be back again.
# if a new worker node is connected to cluster, the new DAEMON POD will be deployed and get the logs and metrics. 
# DaemonSets gets deployed based on the worker nodes.

# we will be copying the yaml from the kubernetes documentation below:
https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/

root@master:~/app/replication# nano daemonsetforworkernodes.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: my-daemonset
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
    spec:
      containers:
      - name: con1
        image: quay.io/fluentd_elasticsearch/fluentd:v2.5.2
root@master:~/app/replication#

root@master:~/app/replication# kubectl create -f daemonsetforworkernodes.yaml
daemonset.apps/my-daemonset created
root@master:~/app/replication# kubectl get daemonsets.apps
NAME           DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE  <-------- we can specify a particular Node, affinity, apply tait toleration to it as well.
my-daemonset   2         2         0       2            0           <none>          7s
root@master:~/app/replication#

### why one daemon is not deployed in the master node? because there is a TAINT on the master node so that nothing on the master node will be deployed. 
root@master:~/app/replication# kkgp
NAME                          READY   STATUS    RESTARTS   AGE
my-daemonset-l5tn2            1/1     Running   0          21s
my-daemonset-mdfjk            1/1     Running   0          21s
newpod                        2/2     Running   0          2d7h
php-apache-598b474864-pchtx   1/1     Running   0          7h3m
root@master:~/app/replication#

### I want to install the daemonSet in the master node as well, what should I do?
### I need to add the TAINT in the DAEMONSET

root@master:~/app/replication# kk describe nodes master | grep -A 2 "Taint"
Taints:             node-role.kubernetes.io/control-plane:NoSchedule
Unschedulable:      false
Lease:
root@master:~/app/replication#

root@master:~/app/replication# nano daemonsetTaintedformasternodes.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: my-daemonset
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
    spec:
      tolerations:
      # these tolerations are to have the daemonset runnable on control plane nodes
      # remove them if your control plane nodes should not run pods
      - key: node-role.kubernetes.io/control-plane
        operator: Exists
        effect: NoSchedule
      containers:
      - name: con1
        image: quay.io/fluentd_elasticsearch/fluentd:v2.5.2
root@master:~/app/replication#


root@master:~/app/replication# kk create -f daemonsetTaintedTolerationformasternodes.yaml
daemonset.apps/my-daemonset created
root@master:~/app/replication#


root@master:~/app/replication# kkgp -o wide
NAME                          READY   STATUS    RESTARTS   AGE     IP               NODE     NOMINATED NODE   READINESS GATES
my-daemonset-2d4c5            1/1     Running   0          38s     172.17.166.187   node1    <none>           <none>
my-daemonset-4qmdz            1/1     Running   0          38s     172.17.219.74    master   <none>           <none>        <------------------- Now with the toleration, it is deployed on the masterNode as well
my-daemonset-lql94            1/1     Running   0          38s     172.17.104.52    node2    <none>           <none>
newpod                        2/2     Running   0          2d12h   172.17.166.168   node1    <none>           <none>
php-apache-598b474864-pchtx   1/1     Running   0          11h     172.17.166.181   node1    <none>           <none>
root@master:~/app/replication#

### if you want to deploy it on the particular node, you can do it from Node Selector. We have covered that in the Scheduling Section
======================================================================================================================================


Volume Type: 
1. emptyDir - is a temporary volume which can be with pod 
2. 

# imagine we have container 1 and 2 in a pod
# how we are connecting one container to another container? 
  # based on the port numbers.
imagine, we have files on con1 and we want to share it on con2
how can we share the these files? We can do that through the emptyDir which can be created through inside the pod. 
you have to mount this emptyDir volume to your container. 
con1
con2




