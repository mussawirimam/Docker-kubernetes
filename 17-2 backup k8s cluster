### taking the backup of the k8s cluster 
root@master:~# kubectl get pods
NAME                    READY   STATUS    RESTARTS   AGE
mango-57b59fd44-ps8ms   1/1     Running   2          2d19h
root@master:~# kubectl deployment apple --image httpd:latest --port 80 --replicas 3
error: unknown command "deployment" for "kubectl"
root@master:~# kubectl create deployment apple --image httpd:latest --port 80 --replicas 3
deployment.apps/apple created
root@master:~# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
apple-86876d998f-48jc9   1/1     Running   0          10s
apple-86876d998f-m8tzv   1/1     Running   0          10s
apple-86876d998f-t298d   1/1     Running   0          10s
mango-57b59fd44-ps8ms    1/1     Running   2          2d19h
root@master:~# kubectl scale deployment apple -- replicas 2
error: required flag(s) "replicas" not set
root@master:~# kubectl scale deployment apple --replicas 2
deployment.apps/apple scaled
root@master:~# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
apple-86876d998f-48jc9   1/1     Running   0          2m14s
apple-86876d998f-m8tzv   1/1     Running   0          2m14s
mango-57b59fd44-ps8ms    1/1     Running   2          2d19h
root@master:~#

### create backup etcd
# if the etcdctl command is not available on the server, it will throw an error. 
example:
ETCDCTL_API=3 etcdctl snnapshot save snapshotdb --endpoints=http://192.168.1.20:2379 --cacert=/etc/Kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/Kubernetes/pki/etcd/server.key

in our case, it should be a private ip address of the master node. Copy it from the aws console. 
ETCDCTL_API=3 etcdctl snnapshot save snapshotdb --endpoints=http://172.31.29.34:2379 --cacert=/etc/Kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/Kubernetes/pki/etcd/server.key


# this is the certificate location and key location which is available on my master node 
# it is needed to authenticate and allow the backup 
--cacert=/etc/Kubernetes/pki/etcd/ca.crt 
--key=/etc/Kubernetes/pki/etcd/server.key

###Installing ETCDCTL
 root@master:~# apt install etcd-client
Reading package lists... Done
Building dependency tree... Done
Reading state information... Done
The following NEW packages will be installed:
  etcd-client
0 upgraded, 1 newly installed, 0 to remove and 67 not upgraded.
Need to get 5297 kB of archives.
After this operation, 17.7 MB of additional disk space will be used.
Get:1 http://us-east-1.ec2.archive.ubuntu.com/ubuntu noble-updates/universe amd64 etcd-client amd64 3.4.30-1ubuntu0.24.04.2 [5297 kB]
Fetched 5297 kB in 1s (8186 kB/s)
Selecting previously unselected package etcd-client.
(Reading database ... 70744 files and directories currently installed.)
Preparing to unpack .../etcd-client_3.4.30-1ubuntu0.24.04.2_amd64.deb ...
Unpacking etcd-client (3.4.30-1ubuntu0.24.04.2) ...
Setting up etcd-client (3.4.30-1ubuntu0.24.04.2) ...
Processing triggers for man-db (2.12.0-4build2) ...
Scanning processes...
Scanning candidates...
Scanning linux images...

Running kernel seems to be up-to-date.

No services need to be restarted.

No containers need to be restarted.

User sessions running outdated binaries:
 ubuntu @ session #1: sshd[2314]

No VM guests are running outdated hypervisor (qemu) binaries on this host.
root@master:~#

### Trouble-shooting time. 

root@master:~# ETCDCTL_API=3 etcdctl --debug snapshot save snapshotdb --endpoints=http://172.31.29.34:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key
ETCDCTL_CACERT=/etc/kubernetes/pki/etcd/ca.crt
ETCDCTL_CERT=/etc/kubernetes/pki/etcd/server.crt
ETCDCTL_COMMAND_TIMEOUT=5s
ETCDCTL_DEBUG=true
ETCDCTL_DIAL_TIMEOUT=2s
ETCDCTL_DISCOVERY_SRV=
ETCDCTL_DISCOVERY_SRV_NAME=
ETCDCTL_ENDPOINTS=[http://172.31.29.34:2379]
ETCDCTL_HEX=false
ETCDCTL_INSECURE_DISCOVERY=true
ETCDCTL_INSECURE_SKIP_TLS_VERIFY=false
ETCDCTL_INSECURE_TRANSPORT=true
ETCDCTL_KEEPALIVE_TIME=2s
ETCDCTL_KEEPALIVE_TIMEOUT=6s
ETCDCTL_KEY=/etc/kubernetes/pki/etcd/server.key
ETCDCTL_PASSWORD=
ETCDCTL_USER=
ETCDCTL_WRITE_OUT=simple
WARNING: 2025/02/06 16:45:41 [core]Adjusting keepalive ping interval to minimum period of 10s
WARNING: 2025/02/06 16:45:41 [core]Adjusting keepalive ping interval to minimum period of 10s
INFO: 2025/02/06 16:45:41 [core]parsed scheme: "etcd-endpoints"
INFO: 2025/02/06 16:45:41 [core]ccResolverWrapper: sending update to cc: {[{172.31.29.34:2379 172.31.29.34:2379 <nil> 0 <nil>}] 0xc00029c360 <nil>}
INFO: 2025/02/06 16:45:41 [core]ClientConn switching balancer to "round_robin"
INFO: 2025/02/06 16:45:41 [core]Channel switches to new LB policy "round_robin"
INFO: 2025/02/06 16:45:41 [balancer]base.baseBalancer: got new ClientConn state: {{[{172.31.29.34:2379 172.31.29.34:2379 <nil> 0 <nil>}] 0xc00029c360 <nil>} <nil>}
INFO: 2025/02/06 16:45:41 [core]Subchannel Connectivity change to CONNECTING
INFO: 2025/02/06 16:45:41 [balancer]base.baseBalancer: handle SubConn state change: 0xc0002a42b0, CONNECTING
INFO: 2025/02/06 16:45:41 [core]Channel Connectivity change to CONNECTING
INFO: 2025/02/06 16:45:41 [core]Subchannel picks a new address "172.31.29.34:2379" to connect
{"level":"info","ts":1738860341.3422008,"caller":"snapshot/v3_snapshot.go:119","msg":"created temporary db file","path":"snapshotdb.part"}
INFO: 2025/02/06 16:45:41 [core]Subchannel Connectivity change to TRANSIENT_FAILURE
INFO: 2025/02/06 16:45:41 [transport]transport: loopyWriter.run returning. connection error: desc = "transport is closing"
INFO: 2025/02/06 16:45:41 [balancer]base.baseBalancer: handle SubConn state change: 0xc0002a42b0, TRANSIENT_FAILURE
INFO: 2025/02/06 16:45:41 [core]Channel Connectivity change to TRANSIENT_FAILURE
INFO: 2025/02/06 16:45:42 [core]Subchannel Connectivity change to CONNECTING
INFO: 2025/02/06 16:45:42 [core]Subchannel picks a new address "172.31.29.34:2379" to connect
INFO: 2025/02/06 16:45:42 [balancer]base.baseBalancer: handle SubConn state change: 0xc0002a42b0, CONNECTING
INFO: 2025/02/06 16:45:42 [core]Subchannel Connectivity change to TRANSIENT_FAILURE
INFO: 2025/02/06 16:45:42 [balancer]base.baseBalancer: handle SubConn state change: 0xc0002a42b0, TRANSIENT_FAILURE
INFO: 2025/02/06 16:45:42 [transport]transport: loopyWriter.run returning. connection error: desc = "transport is closing"
INFO: 2025/02/06 16:45:43 [core]Subchannel Connectivity change to CONNECTING
INFO: 2025/02/06 16:45:43 [core]Subchannel picks a new address "172.31.29.34:2379" to connect
INFO: 2025/02/06 16:45:43 [balancer]base.baseBalancer: handle SubConn state change: 0xc0002a42b0, CONNECTING
INFO: 2025/02/06 16:45:43 [core]Subchannel Connectivity change to TRANSIENT_FAILURE
INFO: 2025/02/06 16:45:43 [balancer]base.baseBalancer: handle SubConn state change: 0xc0002a42b0, TRANSIENT_FAILURE
INFO: 2025/02/06 16:45:43 [transport]transport: loopyWriter.run returning. connection error: desc = "transport is closing"
INFO: 2025/02/06 16:45:46 [core]Subchannel Connectivity change to CONNECTING
INFO: 2025/02/06 16:45:46 [core]Subchannel picks a new address "172.31.29.34:2379" to connect
INFO: 2025/02/06 16:45:46 [balancer]base.baseBalancer: handle SubConn state change: 0xc0002a42b0, CONNECTING
INFO: 2025/02/06 16:45:46 [core]Subchannel Connectivity change to TRANSIENT_FAILURE
INFO: 2025/02/06 16:45:46 [balancer]base.baseBalancer: handle SubConn state change: 0xc0002a42b0, TRANSIENT_FAILURE
INFO: 2025/02/06 16:45:46 [transport]transport: loopyWriter.run returning. connection error: desc = "transport is closing"
